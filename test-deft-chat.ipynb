{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec531e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing k_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing v_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing q_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing out_proj Linear(in_features=4096, out_features=4096, bias=False)\n",
      "Freezing fc_in Linear(in_features=4096, out_features=16384, bias=True)\n",
      "Freezing fc_out Linear(in_features=16384, out_features=4096, bias=True)\n",
      "Freezing lm_head Linear(in_features=4096, out_features=64512, bias=True)\n",
      "Freezing wte Embedding(64512, 4096)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcc9a65e88442a1a5997f74fbc0b3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.cuda.amp import custom_fwd, custom_bwd\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "class FrozenBNBLinear(nn.Module):\n",
    "    def __init__(self, weight, bias=None):\n",
    "        assert isinstance(bias, nn.Parameter) or bias is None\n",
    "        super().__init__()\n",
    "        adapter_dim = 4\n",
    "        p = 0.1\n",
    "        self.out_features, self.in_features = weight.shape\n",
    "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
    "        self.adapter = nn.Sequential(\n",
    "                            nn.Linear(self.in_features, adapter_dim, bias=False),\n",
    "                            nn.Dropout(p=p),\n",
    "                            nn.Linear(adapter_dim, self.out_features, bias=False),\n",
    "                        )\n",
    "        nn.init.zeros_(self.adapter[2].weight)\n",
    "        self.bias = bias\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.linear(input, self.weight, self.bias)\n",
    "        if self.adapter:\n",
    "            output += self.adapter(input)\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
    "\n",
    "class FrozenBNBEmbedding(nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super().__init__()\n",
    "        self.num_embeddings, self.embedding_dim = weight.shape\n",
    "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
    "        adapter_dim = 4\n",
    "        p = 0.1\n",
    "        self.adapter = nn.Sequential(\n",
    "                            nn.Embedding(self.num_embeddings, adapter_dim),\n",
    "                            nn.Dropout(p=p),\n",
    "                            nn.Linear(adapter_dim, self.embedding_dim, bias=False),\n",
    "                        )\n",
    "        nn.init.zeros_(self.adapter[2].weight)\n",
    "\n",
    "    def forward(self, input, **kwargs):\n",
    "        with torch.no_grad():\n",
    "            output = F.embedding(input, self.weight, **kwargs)\n",
    "        if self.adapter:\n",
    "            output += self.adapter(input)\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
    "\n",
    "\n",
    "def freeze_layer(model):\n",
    "    adapter_dim=4\n",
    "    p = 0.1\n",
    "    for module in model.modules():\n",
    "        #print('From', model)\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if name != '0' and name != '2':\n",
    "                    print('Freezing', name, child)\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        name,\n",
    "                        FrozenBNBLinear(\n",
    "                            weight=torch.zeros(child.out_features, child.in_features),\n",
    "                            bias=child.bias,\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "\n",
    "            elif isinstance(child, nn.Embedding):\n",
    "                if name != '0' and name != '2':\n",
    "                    print('Freezing', name, child)\n",
    "                    setattr(\n",
    "                        module,\n",
    "                        name,\n",
    "                        FrozenBNBEmbedding(\n",
    "                            weight=torch.zeros(child.num_embeddings, child.embedding_dim),\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "\n",
    "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        freeze_layer(self.attn)\n",
    "        freeze_layer(self.mlp)\n",
    "\n",
    "\n",
    "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        freeze_layer(self)\n",
    "\n",
    "\n",
    "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        freeze_layer(self)\n",
    "\n",
    "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "     bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]')#, add_bos_token = True, add_eos_token = True)\n",
    "\n",
    "\n",
    "gpt = GPTJForCausalLM.from_pretrained(\n",
    "                    'dilab-cau/deft-korean-alpaca',\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.pad_token_id,\n",
    "                    torch_dtype=torch.float16,\n",
    "                    use_cache=False\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e58f0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): FrozenBNBEmbedding(64512, 4096)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (25): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (26): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (v_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (q_proj): FrozenBNBLinear(4096, 4096)\n",
       "          (out_proj): FrozenBNBLinear(4096, 4096)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): FrozenBNBLinear(4096, 16384)\n",
       "          (fc_out): FrozenBNBLinear(16384, 4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): FrozenBNBLinear(4096, 64512)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:3\"\n",
    "gpt.to(device)\n",
    "gpt.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49b7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def chat():\n",
    "    while(True):\n",
    "        with torch.no_grad():    \n",
    "            text = input('질문: ')\n",
    "            if text == '끝':\n",
    "                break\n",
    "            prompt = '### 명령어:\\n'+text+'\\n\\n### 응답:'\n",
    "            tokens = tokenizer.encode(prompt, return_tensors='pt').to(device=device, non_blocking=True)\n",
    "            gen_tokens = gpt.generate(tokens,\n",
    "                                      do_sample=True,\n",
    "                                      temperature=0.9,                                  top_p=0.99,\n",
    "                                      max_new_tokens=256,\n",
    "                                      early_stopping=True,\n",
    "                                      #num_return_sequences=4, #3개의 결과를 디코딩해낸다\n",
    "                                     )\n",
    "            generated = tokenizer.batch_decode(gen_tokens)[0]\n",
    "            response = generated[len(prompt):].split('[EOS]')[0]\n",
    "            print('답변:',response)\n",
    "            print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145dfed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 다이어트 식단 추천해줘\n",
      "답변: 칼로리는 낮고 단백질이 높은 식단으로 식단을 구성해보세요. 닭가슴살, 달걀, 버섯, 견과류, 브로콜리, 토마토, 두부, 시금치 등 다양한 단백질 식품을 골고루 섭취해보세요. 특히 고구마를 많이 드시면 포만감도 쉽게 유지되고 건강도 챙길 수 있습니다.\n",
      "\n",
      "### 추가로 식단은 무조건 운동과 병행해야 합니다. 운동을 하면서 살을 빼는 것은 불가능하죠. 운동을 하고 난 후에는 살이 안 빠지기 때문에 식사량을 조절하며 운동을 해야 합니다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "질문: 대한민국의 대통령 이름은?\n",
      "답변: 문재인입니다. 문재인은 우리나라 제 19대 대통령입니다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "질문: 끝\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21964d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
